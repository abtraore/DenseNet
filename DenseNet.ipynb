{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "layers = tf.keras.layers\n",
    "weight_decay = tf.keras.regularizers.l2(10e-4)\n",
    "#weight_decay = None\n",
    "useBais = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"  \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0'\n",
    "os.environ[\"TF_FORCE_GPU_ALLOW_GROWTH\"] = \"true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 9469 images belonging to 10 classes.\n",
      "Found 3925 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "# create a new generator\n",
    "imagegen = ImageDataGenerator(rescale=1./255)\n",
    "# load train data\n",
    "train = imagegen.flow_from_directory(\"imagenette2/train/\", class_mode=\"sparse\", shuffle=False, batch_size=24, target_size=(224, 224))\n",
    "# load val data\n",
    "val = imagegen.flow_from_directory(\"imagenette2/val/\", class_mode=\"sparse\", shuffle=False, batch_size=24, target_size=(224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "DenseNet-121\n",
    "\n",
    "- Growth rate (k): 32\n",
    "- Compression rate: 0.5\n",
    "- Blocks: [6,12,24,16]\n",
    "\n",
    "'''\n",
    "\n",
    "class DenseNet(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(DenseNet,self).__init__()\n",
    "            \n",
    "        \n",
    "    def dense_block(self,x,block):\n",
    "        \n",
    "        for i in range(block):\n",
    "            x = self.composite(x,32)        \n",
    "        return x\n",
    "        \n",
    "    def composite(self,x,growth_rate):\n",
    "        \n",
    "        x_0 = x\n",
    "        \n",
    "        x = layers.BatchNormalization(epsilon=1.001e-5)(x)\n",
    "        x = layers.Activation(\"relu\")(x)\n",
    "        x = layers.Conv2D(4*growth_rate,1,use_bias=useBais, kernel_regularizer= weight_decay,kernel_initializer=\"he_normal\")(x)\n",
    "        x = layers.BatchNormalization(epsilon=1.001e-5)(x)\n",
    "        x = layers.Activation(\"relu\")(x)\n",
    "        x = layers.Conv2D(growth_rate,3,padding=\"same\",use_bias=useBais, kernel_regularizer= weight_decay,kernel_initializer=\"he_normal\")(x)\n",
    "        \n",
    "        x = layers.Concatenate()([x_0,x])\n",
    "        \n",
    "        return x\n",
    "    \n",
    "        \n",
    "    def transition(self,x,compression):\n",
    "        \n",
    "        x = layers.BatchNormalization(epsilon=1.001e-5)(x)\n",
    "        x = layers.Activation(\"relu\")(x)\n",
    "        x = layers.Conv2D(int(x.shape[-1] * compression),1,use_bias=useBais, kernel_regularizer= weight_decay,kernel_initializer=\"he_normal\")(x)\n",
    "        x = layers.AveragePooling2D(2,strides=2)(x)\n",
    "        \n",
    "        return x\n",
    "        \n",
    "    def call(self,x):\n",
    "        \n",
    "        x = layers.ZeroPadding2D(padding=((3, 3), (3, 3)))(x)\n",
    "        x = layers.Conv2D(64, 7, strides=2, use_bias=useBais, kernel_regularizer= weight_decay,kernel_initializer=\"he_normal\")(x)# = 2*k = 2 * 32 = 64.\n",
    "        x = layers.BatchNormalization(axis=-1, epsilon=1.001e-5)(x)\n",
    "        x = layers.Activation('relu', name='conv1/relu')(x)\n",
    "        x = layers.ZeroPadding2D(padding=((1, 1), (1, 1)))(x)\n",
    "        x = layers.MaxPooling2D(3, strides=2, name='pool1')(x)\n",
    "        \n",
    "        \n",
    "        x = self.dense_block(x,6)\n",
    "        x = self.transition(x,0.5)\n",
    "        x = self.dense_block(x,12)\n",
    "        x = self.transition(x,0.5)\n",
    "        x = self.dense_block(x,24)\n",
    "        x = self.transition(x,0.5)\n",
    "        x = self.dense_block(x,16)\n",
    "        \n",
    "        x = layers.BatchNormalization(axis=-1, epsilon=1.001e-5)(x)\n",
    "        x = layers.Activation('relu')(x)\n",
    "        \n",
    "        x = layers.GlobalAveragePooling2D()(x)\n",
    "        x = layers.Dense(10,activation=\"sigmoid\")(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "FUNCTIONAL API IMPLEMENTATION\n",
    "\n",
    "DenseNet-121\n",
    "\n",
    "- Growth rate (k): 32\n",
    "- Compression rate: 0.5\n",
    "- Blocks: [6,12,24,16]\n",
    "\n",
    "'''\n",
    "def dense_block(x,block):\n",
    "\n",
    "    for i in range(block):\n",
    "        x = composite(x,32)        \n",
    "    return x\n",
    "        \n",
    "def composite(x,growth_rate):\n",
    "\n",
    "    x_0 = x\n",
    "\n",
    "    x = layers.BatchNormalization(epsilon=1.001e-5)(x)\n",
    "    x = layers.Activation(\"relu\")(x)\n",
    "    x = layers.Conv2D(4*growth_rate,1,use_bias=useBais, kernel_regularizer= weight_decay)(x)\n",
    "    x = layers.Dropout(0.2)(x)\n",
    "    \n",
    "    x = layers.BatchNormalization(epsilon=1.001e-5)(x)\n",
    "    x = layers.Activation(\"relu\")(x)\n",
    "    x = layers.Conv2D(growth_rate,3,padding=\"same\",use_bias=useBais, kernel_regularizer= weight_decay)(x)\n",
    "    x = layers.Dropout(0.2)(x)\n",
    "\n",
    "    x = layers.Concatenate()([x_0,x])\n",
    "\n",
    "    return x\n",
    "    \n",
    "\n",
    "def transition(x,compression):\n",
    "\n",
    "    x = layers.BatchNormalization(epsilon=1.001e-5)(x)\n",
    "    x = layers.Activation(\"relu\")(x)\n",
    "    x = layers.Conv2D(int(x.shape[-1] * compression),1,use_bias=useBais, kernel_regularizer= weight_decay)(x)\n",
    "    x = layers.Dropout(0.2)(x)\n",
    "    x = layers.AveragePooling2D(2,strides=2)(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "def DenseNetS():\n",
    "        \n",
    "    inputs = tf.keras.layers.Input(shape=(224,244,3))\n",
    "    x = layers.ZeroPadding2D(padding=((3, 3), (3, 3)))(inputs)\n",
    "    x = layers.Conv2D(64, 7, strides=2, use_bias=useBais, kernel_regularizer= weight_decay)(x)# = 2*k = 2 * 32 = 64.\n",
    "    x = layers.BatchNormalization(axis=-1, epsilon=1.001e-5)(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    x = layers.ZeroPadding2D(padding=((1, 1), (1, 1)))(x)\n",
    "    x = layers.MaxPooling2D(3, strides=2,)(x)\n",
    "\n",
    "\n",
    "    x = dense_block(x,6)\n",
    "    x = transition(x,0.5)\n",
    "    x = dense_block(x,12)\n",
    "    x = transition(x,0.5)\n",
    "    x = dense_block(x,24)\n",
    "    x = transition(x,0.5)\n",
    "    x = dense_block(x,16)\n",
    "\n",
    "    x = layers.BatchNormalization(axis=-1, epsilon=1.001e-5)(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    x = layers.Dense(10,activation=\"softmax\")(x)\n",
    "\n",
    "    return tf.keras.Model(inputs,x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "395/395 [==============================] - 97s 245ms/step - loss: 17.8597 - acc: 0.0936 - val_loss: 17.8575 - val_acc: 0.1297\n",
      "Epoch 2/100\n",
      "395/395 [==============================] - 97s 245ms/step - loss: 17.8318 - acc: 0.0881 - val_loss: 17.8020 - val_acc: 0.0813\n",
      "Epoch 3/100\n",
      "395/395 [==============================] - 98s 247ms/step - loss: 17.8053 - acc: 0.0835 - val_loss: 17.7967 - val_acc: 0.0828\n",
      "Epoch 4/100\n",
      "395/395 [==============================] - 98s 248ms/step - loss: 17.7805 - acc: 0.0787 - val_loss: 17.7597 - val_acc: 0.0884\n",
      "Epoch 5/100\n",
      "395/395 [==============================] - 98s 249ms/step - loss: 17.7536 - acc: 0.0978 - val_loss: 17.7318 - val_acc: 0.0713\n",
      "Epoch 6/100\n",
      "395/395 [==============================] - 98s 248ms/step - loss: 17.7239 - acc: 0.1000 - val_loss: 17.7161 - val_acc: 0.1042\n",
      "Epoch 7/100\n",
      "395/395 [==============================] - 99s 249ms/step - loss: 17.7077 - acc: 0.0828 - val_loss: 17.6835 - val_acc: 0.0708\n",
      "Epoch 8/100\n",
      "395/395 [==============================] - 98s 248ms/step - loss: 17.6708 - acc: 0.1065 - val_loss: 17.6817 - val_acc: 0.0785\n",
      "Epoch 9/100\n",
      "395/395 [==============================] - 98s 249ms/step - loss: 17.6521 - acc: 0.0961 - val_loss: 17.6602 - val_acc: 0.0670\n",
      "Epoch 10/100\n",
      "395/395 [==============================] - 98s 249ms/step - loss: 17.6299 - acc: 0.0933 - val_loss: 17.6058 - val_acc: 0.0795\n",
      "Epoch 11/100\n",
      "395/395 [==============================] - 98s 249ms/step - loss: 17.6062 - acc: 0.0886 - val_loss: 17.5864 - val_acc: 0.0741\n",
      "Epoch 12/100\n",
      "395/395 [==============================] - 98s 249ms/step - loss: 17.5729 - acc: 0.0886 - val_loss: 17.5577 - val_acc: 0.0874\n",
      "Epoch 13/100\n",
      "395/395 [==============================] - 98s 249ms/step - loss: 17.5451 - acc: 0.1022 - val_loss: 17.5295 - val_acc: 0.0871\n",
      "Epoch 14/100\n",
      "395/395 [==============================] - 98s 249ms/step - loss: 17.5219 - acc: 0.0988 - val_loss: 17.5120 - val_acc: 0.0810\n",
      "Epoch 15/100\n",
      "395/395 [==============================] - 98s 249ms/step - loss: 17.4951 - acc: 0.1202 - val_loss: 17.4971 - val_acc: 0.0848\n",
      "Epoch 16/100\n",
      "395/395 [==============================] - 98s 249ms/step - loss: 17.4709 - acc: 0.1099 - val_loss: 17.4855 - val_acc: 0.0871\n",
      "Epoch 17/100\n",
      "395/395 [==============================] - 98s 248ms/step - loss: 17.4482 - acc: 0.1098 - val_loss: 17.4563 - val_acc: 0.0782\n",
      "Epoch 18/100\n",
      "395/395 [==============================] - 98s 248ms/step - loss: 17.4227 - acc: 0.1070 - val_loss: 17.4310 - val_acc: 0.0892\n",
      "Epoch 19/100\n",
      "395/395 [==============================] - 98s 249ms/step - loss: 17.3969 - acc: 0.1084 - val_loss: 17.4053 - val_acc: 0.1001\n",
      "Epoch 20/100\n",
      "395/395 [==============================] - 98s 248ms/step - loss: 17.3720 - acc: 0.1024 - val_loss: 17.3909 - val_acc: 0.0925\n",
      "Epoch 21/100\n",
      "395/395 [==============================] - 98s 248ms/step - loss: 17.3422 - acc: 0.1254 - val_loss: 17.3596 - val_acc: 0.0764\n",
      "Epoch 22/100\n",
      "395/395 [==============================] - 99s 250ms/step - loss: 17.3129 - acc: 0.1206 - val_loss: 17.3453 - val_acc: 0.0831\n",
      "Epoch 23/100\n",
      "395/395 [==============================] - 98s 249ms/step - loss: 17.2944 - acc: 0.1166 - val_loss: 17.3052 - val_acc: 0.0927\n",
      "Epoch 24/100\n",
      "395/395 [==============================] - 98s 249ms/step - loss: 17.2537 - acc: 0.1335 - val_loss: 17.2959 - val_acc: 0.0856\n",
      "Epoch 25/100\n",
      "395/395 [==============================] - 98s 249ms/step - loss: 17.2375 - acc: 0.1385 - val_loss: 17.2609 - val_acc: 0.0910\n",
      "Epoch 26/100\n",
      "395/395 [==============================] - 98s 249ms/step - loss: 17.2116 - acc: 0.1393 - val_loss: 17.2460 - val_acc: 0.0782\n",
      "Epoch 27/100\n",
      "395/395 [==============================] - 99s 250ms/step - loss: 17.1813 - acc: 0.1601 - val_loss: 17.2203 - val_acc: 0.0861\n",
      "Epoch 28/100\n",
      "395/395 [==============================] - 98s 249ms/step - loss: 17.1514 - acc: 0.1564 - val_loss: 17.1863 - val_acc: 0.0897\n",
      "Epoch 29/100\n",
      "395/395 [==============================] - 98s 249ms/step - loss: 17.1314 - acc: 0.1391 - val_loss: 17.1734 - val_acc: 0.0889\n",
      "Epoch 30/100\n",
      "395/395 [==============================] - 98s 249ms/step - loss: 17.0950 - acc: 0.1521 - val_loss: 17.1565 - val_acc: 0.0828\n",
      "Epoch 31/100\n",
      "395/395 [==============================] - 98s 249ms/step - loss: 17.0677 - acc: 0.1565 - val_loss: 17.1411 - val_acc: 0.0920\n",
      "Epoch 32/100\n",
      "395/395 [==============================] - 98s 249ms/step - loss: 17.0368 - acc: 0.1840 - val_loss: 17.1213 - val_acc: 0.0897\n",
      "Epoch 33/100\n",
      "395/395 [==============================] - 98s 249ms/step - loss: 17.0155 - acc: 0.1703 - val_loss: 17.0893 - val_acc: 0.0989\n",
      "Epoch 34/100\n",
      "395/395 [==============================] - 98s 249ms/step - loss: 16.9843 - acc: 0.1917 - val_loss: 17.0907 - val_acc: 0.0894\n",
      "Epoch 35/100\n",
      "395/395 [==============================] - 98s 249ms/step - loss: 16.9587 - acc: 0.1828 - val_loss: 17.0306 - val_acc: 0.0955\n",
      "Epoch 36/100\n",
      "395/395 [==============================] - 98s 249ms/step - loss: 16.9395 - acc: 0.1724 - val_loss: 17.0194 - val_acc: 0.0927\n",
      "Epoch 37/100\n",
      "395/395 [==============================] - 99s 250ms/step - loss: 16.9093 - acc: 0.2040 - val_loss: 17.0093 - val_acc: 0.0907\n",
      "Epoch 38/100\n",
      "395/395 [==============================] - 99s 249ms/step - loss: 16.8749 - acc: 0.2125 - val_loss: 16.9808 - val_acc: 0.0815\n",
      "Epoch 39/100\n",
      "395/395 [==============================] - 99s 250ms/step - loss: 16.8547 - acc: 0.1883 - val_loss: 16.9623 - val_acc: 0.0945\n",
      "Epoch 40/100\n",
      "395/395 [==============================] - 99s 250ms/step - loss: 16.8169 - acc: 0.2126 - val_loss: 16.9542 - val_acc: 0.0892\n",
      "Epoch 41/100\n",
      "395/395 [==============================] - 99s 249ms/step - loss: 16.7949 - acc: 0.1951 - val_loss: 16.9024 - val_acc: 0.0961\n",
      "Epoch 42/100\n",
      "395/395 [==============================] - 99s 250ms/step - loss: 16.7692 - acc: 0.2083 - val_loss: 16.9113 - val_acc: 0.0757\n",
      "Epoch 43/100\n",
      "395/395 [==============================] - 98s 249ms/step - loss: 16.7261 - acc: 0.2262 - val_loss: 16.8872 - val_acc: 0.0915\n",
      "Epoch 44/100\n",
      "395/395 [==============================] - 99s 250ms/step - loss: 16.7031 - acc: 0.2323 - val_loss: 16.8541 - val_acc: 0.0925\n",
      "Epoch 45/100\n",
      "395/395 [==============================] - 98s 249ms/step - loss: 16.6815 - acc: 0.2323 - val_loss: 16.8172 - val_acc: 0.0879\n",
      "Epoch 46/100\n",
      "395/395 [==============================] - 99s 250ms/step - loss: 16.6412 - acc: 0.2554 - val_loss: 16.8532 - val_acc: 0.0825\n",
      "Epoch 47/100\n",
      "395/395 [==============================] - 99s 250ms/step - loss: 16.6164 - acc: 0.2511 - val_loss: 16.7734 - val_acc: 0.0955\n",
      "Epoch 48/100\n",
      "395/395 [==============================] - 99s 250ms/step - loss: 16.5876 - acc: 0.2516 - val_loss: 16.7454 - val_acc: 0.1032\n",
      "Epoch 49/100\n",
      "395/395 [==============================] - 98s 249ms/step - loss: 16.5501 - acc: 0.2709 - val_loss: 16.7721 - val_acc: 0.0782\n",
      "Epoch 50/100\n",
      "395/395 [==============================] - 99s 250ms/step - loss: 16.5284 - acc: 0.2583 - val_loss: 16.7319 - val_acc: 0.0915\n",
      "Epoch 51/100\n",
      "395/395 [==============================] - 98s 249ms/step - loss: 16.4977 - acc: 0.2606 - val_loss: 16.7095 - val_acc: 0.0907\n",
      "Epoch 52/100\n",
      "395/395 [==============================] - 99s 250ms/step - loss: 16.4634 - acc: 0.2770 - val_loss: 16.6901 - val_acc: 0.0815\n",
      "Epoch 53/100\n",
      "395/395 [==============================] - 99s 250ms/step - loss: 16.4273 - acc: 0.2689 - val_loss: 16.6772 - val_acc: 0.0938\n",
      "Epoch 54/100\n",
      "169/395 [===========>..................] - ETA: 48s - loss: 16.4040 - acc: 0.2850"
     ]
    }
   ],
   "source": [
    "model = DenseNetS()\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",optimizer=tf.keras.optimizers.SGD(lr=0.0001,nesterov=True,momentum=0.9),metrics=\"acc\")\n",
    "model.fit(train,validation_data=val,epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
